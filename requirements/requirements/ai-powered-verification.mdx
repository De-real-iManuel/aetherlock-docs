# AI-Powered Verification

## Overview

This document defines the comprehensive requirements for AetherLock's AI-powered Proof of Task Verification (PoTv) system. The system leverages AWS Bedrock's Claude foundation model to automatically analyze task completion evidence and make verification decisions, enabling fast, unbiased, and cost-effective escrow resolution.

## User Stories and Acceptance Criteria

### User Story 1: Freelancer Submits Work for AI Verification

**As a** freelancer who has completed work  
**I want** an AI system to automatically verify my task completion by analyzing submitted evidence  
**So that** I can receive payment quickly without waiting for manual review or potential human bias

#### Acceptance Criteria

1. **WHEN** I submit evidence for verification **THEN** the system SHALL trigger the AI verification pipeline within 5 seconds
2. **WHEN** the AI begins analysis **THEN** the system SHALL display a real-time progress indicator showing verification status
3. **WHEN** verification completes **THEN** the system SHALL display the result (Approved, Rejected, or Needs Review) with confidence score
4. **WHEN** my work is approved **THEN** the system SHALL automatically release funds to my wallet within 15 seconds
5. **WHEN** verification fails **THEN** the system SHALL provide detailed AI-generated feedback explaining what requirements were not met

### User Story 2: AWS Bedrock Integration and Model Selection

**As the** AetherLock protocol  
**I want to** integrate with AWS Bedrock's Claude model for natural language understanding  
**So that** I can leverage state-of-the-art AI capabilities for accurate task verification

#### Acceptance Criteria

1. **WHEN** the system initializes **THEN** it SHALL establish a connection to AWS Bedrock using IAM role-based authentication
2. **WHEN** a verification request is made **THEN** the system SHALL use Claude 3 Sonnet as the primary model for analysis
3. **WHEN** Bedrock API calls are made **THEN** the system SHALL include proper request headers, model parameters, and timeout configurations
4. **WHEN** the API response is received **THEN** the system SHALL parse the JSON response and extract the verification decision and confidence score
5. **WHEN** Bedrock is unavailable **THEN** the system SHALL fall back to Arcanum AI, then OpenAI, then Claude API in sequence

### User Story 3: Multi-Format Evidence Analysis Pipeline

**As the** AI verification system  
**I want to** process multiple evidence types including text, images, documents, and URLs  
**So that** I can comprehensively evaluate task completion regardless of submission format

#### Acceptance Criteria

1. **WHEN** text evidence is submitted **THEN** the system SHALL retrieve the content from IPFS and include it in the AI prompt
2. **WHEN** image evidence is submitted **THEN** the system SHALL use Claude's vision capabilities to analyze the image content
3. **WHEN** document evidence is submitted (PDF, DOCX) **THEN** the system SHALL extract text content and include it in the analysis
4. **WHEN** URL evidence is submitted **THEN** the system SHALL fetch the webpage content and analyze it for task completion indicators
5. **WHEN** multiple evidence files are submitted **THEN** the system SHALL analyze all files and generate a comprehensive verification report

### User Story 4: Evidence Preprocessing and Optimization

**As the** evidence analysis pipeline  
**I want to** preprocess and optimize evidence before sending to the AI model  
**So that** I can maximize analysis accuracy while minimizing API costs and latency

#### Acceptance Criteria

1. **WHEN** large files are submitted **THEN** the system SHALL chunk content into segments of maximum 100KB each
2. **WHEN** images are submitted **THEN** the system SHALL resize images to maximum 1024x1024 pixels while preserving aspect ratio
3. **WHEN** documents contain irrelevant content **THEN** the system SHALL extract only task-relevant sections using keyword matching
4. **WHEN** evidence is retrieved from IPFS **THEN** the system SHALL cache content locally to avoid redundant IPFS fetches
5. **WHEN** preprocessing fails **THEN** the system SHALL log the error and attempt verification with raw evidence as fallback

### User Story 5: Intelligent Verification Decision Logic

**As the** verification decision engine  
**I want to** categorize AI results into Approved, Rejected, or Needs Review based on confidence thresholds  
**So that** I can automate high-confidence decisions while routing uncertain cases to human review

#### Acceptance Criteria

1. **WHEN** AI confidence is above 90% **THEN** the system SHALL automatically approve the verification and release funds
2. **WHEN** AI confidence is between 50% and 90% **THEN** the system SHALL mark the verification as "Needs Review" and notify human reviewers
3. **WHEN** AI confidence is below 50% **THEN** the system SHALL automatically reject the verification with detailed feedback
4. **WHEN** the decision is made **THEN** the system SHALL emit a VerificationCompleted event with decision, confidence, and reasoning
5. **WHEN** the decision is logged **THEN** the system SHALL store the complete AI response on-chain as an Ed25519-signed message for auditability

### User Story 6: Prompt Engineering and Context Building

**As the** AI prompt builder  
**I want to** construct detailed prompts that include task requirements, evidence, and evaluation criteria  
**So that** the AI model has sufficient context to make accurate verification decisions

#### Acceptance Criteria

1. **WHEN** building the prompt **THEN** the system SHALL include the original task description from the escrow contract
2. **WHEN** building the prompt **THEN** the system SHALL include all submitted evidence with clear labels and formatting
3. **WHEN** building the prompt **THEN** the system SHALL include specific evaluation criteria such as completeness, quality, and requirement matching
4. **WHEN** building the prompt **THEN** the system SHALL request a structured JSON response with decision, confidence, and reasoning fields
5. **WHEN** the prompt exceeds token limits **THEN** the system SHALL prioritize the most relevant evidence and truncate less important content

### User Story 7: AI Result Authentication and Security

**As a** security-conscious user  
**I want** AI verification results to be cryptographically signed  
**So that** I can verify the authenticity of verification decisions and prevent tampering

#### Acceptance Criteria

1. **WHEN** the AI generates a verification result **THEN** the system SHALL create an Ed25519 signature of the result using the AI service's private key
2. **WHEN** the result is stored on-chain **THEN** the system SHALL include the signature alongside the verification decision
3. **WHEN** a user queries verification results **THEN** the system SHALL provide the signature for independent verification
4. **WHEN** signature verification is performed **THEN** the system SHALL use the AI service's public key to validate authenticity
5. **WHEN** signature verification fails **THEN** the system SHALL reject the result and trigger a re-verification

### User Story 8: Feedback Generation and Iteration Support

**As a** freelancer whose work was rejected  
**I want** detailed AI-generated feedback explaining what was missing  
**So that** I can improve my submission and resubmit for verification

#### Acceptance Criteria

1. **WHEN** my work is rejected **THEN** the system SHALL generate specific feedback identifying which task requirements were not met
2. **WHEN** feedback is generated **THEN** the system SHALL include actionable suggestions for improvement
3. **WHEN** I view the feedback **THEN** the system SHALL display it in a clear, structured format with bullet points
4. **WHEN** I resubmit evidence **THEN** the system SHALL include the previous feedback in the AI prompt to check for improvements
5. **WHEN** multiple resubmissions occur **THEN** the system SHALL track the iteration history and display progress over time

### User Story 9: Performance Optimization and Caching

**As the** verification system  
**I want to** optimize AI verification performance through caching and parallel processing  
**So that** I can handle high volumes of verification requests efficiently

#### Acceptance Criteria

1. **WHEN** identical evidence is submitted multiple times **THEN** the system SHALL return cached verification results without calling the AI API
2. **WHEN** multiple verification requests arrive simultaneously **THEN** the system SHALL process them in parallel up to a concurrency limit of 10
3. **WHEN** verification completes **THEN** the system SHALL cache the result for 24 hours with the evidence hash as the cache key
4. **WHEN** the cache is full **THEN** the system SHALL evict the least recently used entries to make space for new results
5. **WHEN** verification takes longer than 30 seconds **THEN** the system SHALL return a timeout error and queue the request for retry

### User Story 10: Error Handling and Fallback Mechanisms

**As the** verification system  
**I want** robust error handling and fallback mechanisms  
**So that** verification requests succeed even when primary services are unavailable

#### Acceptance Criteria

1. **WHEN** AWS Bedrock returns an error **THEN** the system SHALL retry the request up to 3 times with exponential backoff
2. **WHEN** all Bedrock retries fail **THEN** the system SHALL fall back to Arcanum AI as the secondary provider
3. **WHEN** Arcanum AI fails **THEN** the system SHALL fall back to OpenAI API as the tertiary provider
4. **WHEN** all AI providers fail **THEN** the system SHALL mark the verification as "Needs Review" and notify administrators
5. **WHEN** rate limits are hit **THEN** the system SHALL queue the request and retry after the rate limit window expires

### User Story 11: Verification Analytics and Model Improvement

**As a** system administrator  
**I want** to track verification accuracy and collect feedback for model improvement  
**So that** I can continuously enhance the AI verification system

#### Acceptance Criteria

1. **WHEN** verifications are completed **THEN** the system SHALL log the decision, confidence, and processing time to analytics
2. **WHEN** disputes are resolved **THEN** the system SHALL compare the AI decision with the human arbitrator decision
3. **WHEN** discrepancies are found **THEN** the system SHALL flag the case for prompt engineering review
4. **WHEN** accuracy metrics are calculated **THEN** the system SHALL display overall accuracy, precision, and recall on the admin dashboard
5. **WHEN** model performance degrades **THEN** the system SHALL send alerts to administrators for investigation

## Technical Requirements

### AWS Bedrock Integration

#### API Configuration
- **Model**: Claude 3 Sonnet (anthropic.claude-3-sonnet-20240229-v1:0)
- **Region**: us-east-1 (primary), us-west-2 (fallback)
- **Authentication**: IAM role-based authentication with least-privilege permissions
- **Timeout**: 30 seconds per API call
- **Max Tokens**: 4096 tokens for response generation

#### Request Structure
```json
{
  "modelId": "anthropic.claude-3-sonnet-20240229-v1:0",
  "contentType": "application/json",
  "accept": "application/json",
  "body": {
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 4096,
    "messages": [
      {
        "role": "user",
        "content": "<prompt>"
      }
    ],
    "temperature": 0.3,
    "top_p": 0.9
  }
}
```

#### Response Parsing
- Extract verification decision from structured JSON response
- Parse confidence score as a float between 0.0 and 1.0
- Extract reasoning text for feedback generation
- Handle malformed responses with error recovery

### Evidence Analysis Pipeline

#### Supported Evidence Types
- **Text**: Plain text, markdown, code snippets
- **Images**: JPEG, PNG, WebP (max 5MB per image)
- **Documents**: PDF, DOCX, TXT (max 10MB per document)
- **URLs**: Web pages, GitHub repositories, deployed applications

#### Processing Steps
1. **Retrieval**: Fetch evidence from IPFS using the stored CID
2. **Validation**: Check file size, format, and content type
3. **Preprocessing**: Extract text, resize images, chunk large files
4. **Prompt Construction**: Build comprehensive prompt with task context and evidence
5. **AI Analysis**: Send prompt to AWS Bedrock and await response
6. **Result Processing**: Parse response, calculate confidence, generate feedback
7. **Storage**: Store result on-chain with Ed25519 signature

### Verification Decision Logic

#### Confidence Thresholds
- **High Confidence (≥90%)**: Automatic approval, immediate fund release
- **Medium Confidence (50-89%)**: Human review required, funds remain locked
- **Low Confidence (<50%)**: Automatic rejection, detailed feedback provided

#### Decision Factors
- **Requirement Matching**: Does evidence demonstrate all task requirements are met?
- **Quality Assessment**: Is the work quality acceptable for the agreed payment?
- **Completeness**: Are all deliverables present and functional?
- **Authenticity**: Does the evidence appear genuine and not plagiarized?

### Performance Requirements
- **Verification Latency**: Complete verification within 30 seconds for 95% of requests
- **Throughput**: Handle 100 concurrent verification requests
- **Cache Hit Rate**: Achieve 20% cache hit rate for duplicate evidence
- **API Cost**: Keep average cost per verification below $0.10

### Security Requirements
- **Signature Verification**: All AI results signed with Ed25519 private key
- **Input Validation**: Sanitize all evidence to prevent prompt injection attacks
- **Rate Limiting**: Limit verification requests to 10 per user per minute
- **Access Control**: Only escrow participants can trigger verification

### Error Handling Requirements
- **Retry Logic**: Exponential backoff with jitter (1s, 2s, 4s delays)
- **Fallback Chain**: Bedrock → Arcanum → OpenAI → Claude API → Human Review
- **Timeout Handling**: Return timeout error after 30 seconds, queue for retry
- **Error Logging**: Log all errors with request ID, timestamp, and error details

## Integration Points

### IPFS Integration
- Retrieve evidence files using IPFS CID
- Cache retrieved content locally for 1 hour
- Handle IPFS gateway failures with multiple gateway fallbacks

### Smart Contract Integration
- Read escrow task description and requirements from on-chain state
- Write verification result to escrow account with signature
- Emit VerificationCompleted event for off-chain indexing

### Notification Service Integration
- Send real-time notifications to freelancer when verification completes
- Send notifications to client when human review is required
- Send alerts to administrators when all AI providers fail

### Analytics Integration
- Log verification metrics (latency, confidence, decision) to analytics database
- Track AI provider usage and costs
- Monitor accuracy through dispute resolution feedback loop
