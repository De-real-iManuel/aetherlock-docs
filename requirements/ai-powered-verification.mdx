# AI-Powered Verification

## Overview

This document defines the comprehensive requirements for AetherLock's AI-powered Proof of Task Verification (PoTV) system. The system leverages Arcanum.ai as the primary AI provider to automatically analyze task completion evidence and make verification decisions, enabling fast, unbiased, and cost-effective escrow resolution.

## Implementation Status

### Current Features (Implemented - Devnet)
- âœ… **D-PoTV (Digital Proof-of-Task Verification)**: AI verification for digital deliverables (code, design, writing, data)
- âœ… **Arcanum.ai Integration**: Primary AI provider for task verification
- âœ… **Basic Evidence Analysis**: Text and document analysis
- âœ… **Confidence-Based Decisions**: Automatic approval/rejection based on confidence thresholds
- âœ… **On-Chain Result Storage**: Verification results stored in escrow accounts

### Planned Features (Future Roadmap)
- ðŸ”„ **AI Fallback Chain**: Arcanum.ai â†’ OpenAI â†’ Claude â†’ Gemini for high availability
- ðŸ”„ **Multi-Format Evidence**: Image analysis, video processing, URL scraping
- ðŸ”„ **Ed25519 Signature Verification**: Cryptographic authentication of AI results
- ðŸ”„ **Advanced Preprocessing**: Image resizing, document chunking, content optimization
- ðŸ”„ **Caching Layer**: Redis-based caching for duplicate evidence
- ðŸ”„ **Human Review Queue**: Low-confidence cases routed to human arbitrators
- ðŸ”„ **Feedback Loop**: Dispute resolution feedback for model improvement

## User Stories and Acceptance Criteria

### User Story 1: Freelancer Submits Work for AI Verification

**As a** freelancer who has completed work  
**I want** an AI system to automatically verify my task completion by analyzing submitted evidence  
**So that** I can receive payment quickly without waiting for manual review or potential human bias

#### Acceptance Criteria

1. **WHEN** I submit evidence for verification **THEN** the system SHALL trigger the AI verification pipeline within 5 seconds
2. **WHEN** the AI begins analysis **THEN** the system SHALL display a real-time progress indicator showing verification status
3. **WHEN** verification completes **THEN** the system SHALL display the result (Approved, Rejected, or Needs Review) with confidence score
4. **WHEN** my work is approved **THEN** the system SHALL automatically release funds to my wallet within 15 seconds
5. **WHEN** verification fails **THEN** the system SHALL provide detailed AI-generated feedback explaining what requirements were not met

### User Story 2: Arcanum.ai Integration and Model Selection

**Implementation Status**: âœ… **IMPLEMENTED (Devnet)** - Arcanum.ai is the current AI provider

**As the** AetherLock protocol  
**I want to** integrate with Arcanum.ai for specialized task verification analysis  
**So that** I can leverage purpose-built AI capabilities for accurate and efficient task verification

#### Acceptance Criteria

1. âœ… **WHEN** the system initializes **THEN** it SHALL establish a connection to Arcanum.ai using API key authentication
2. âœ… **WHEN** a verification request is made **THEN** the system SHALL use Arcanum.ai as the primary provider for analysis
3. âœ… **WHEN** Arcanum.ai API calls are made **THEN** the system SHALL include proper request headers, authentication tokens, and timeout configurations
4. âœ… **WHEN** the API response is received **THEN** the system SHALL parse the JSON response and extract the verification decision and confidence score
5. ðŸ”„ **WHEN** Arcanum.ai is unavailable **THEN** the system SHALL fall back to OpenAI, then Claude, then Gemini in sequence *(PLANNED - No fallback chain currently implemented)*

### User Story 3: Multi-Format Evidence Analysis Pipeline

**Implementation Status**: ðŸ”„ **PARTIALLY IMPLEMENTED** - Text and basic documents supported, advanced formats planned

**As the** AI verification system  
**I want to** process multiple evidence types including text, images, documents, and URLs  
**So that** I can comprehensively evaluate task completion regardless of submission format

#### Acceptance Criteria

1. âœ… **WHEN** text evidence is submitted **THEN** the system SHALL retrieve the content from IPFS and include it in the AI prompt *(IMPLEMENTED)*
2. ðŸ”„ **WHEN** image evidence is submitted **THEN** the system SHALL use Claude's vision capabilities to analyze the image content *(PLANNED - Requires AI fallback chain)*
3. âœ… **WHEN** document evidence is submitted (PDF, DOCX) **THEN** the system SHALL extract text content and include it in the analysis *(BASIC IMPLEMENTATION)*
4. ðŸ”„ **WHEN** URL evidence is submitted **THEN** the system SHALL fetch the webpage content and analyze it for task completion indicators *(PLANNED)*
5. ðŸ”„ **WHEN** multiple evidence files are submitted **THEN** the system SHALL analyze all files and generate a comprehensive verification report *(PLANNED)*

### User Story 4: Evidence Preprocessing and Optimization

**As the** evidence analysis pipeline  
**I want to** preprocess and optimize evidence before sending to the AI model  
**So that** I can maximize analysis accuracy while minimizing API costs and latency

#### Acceptance Criteria

1. **WHEN** large files are submitted **THEN** the system SHALL chunk content into segments of maximum 100KB each
2. **WHEN** images are submitted **THEN** the system SHALL resize images to maximum 1024x1024 pixels while preserving aspect ratio
3. **WHEN** documents contain irrelevant content **THEN** the system SHALL extract only task-relevant sections using keyword matching
4. **WHEN** evidence is retrieved from IPFS **THEN** the system SHALL cache content locally to avoid redundant IPFS fetches
5. **WHEN** preprocessing fails **THEN** the system SHALL log the error and attempt verification with raw evidence as fallback

### User Story 5: Intelligent Verification Decision Logic

**As the** verification decision engine  
**I want to** categorize AI results into Approved, Rejected, or Needs Review based on confidence thresholds  
**So that** I can automate high-confidence decisions while routing uncertain cases to human review

#### Acceptance Criteria

1. **WHEN** AI confidence is above 90% **THEN** the system SHALL automatically approve the verification and release funds
2. **WHEN** AI confidence is between 50% and 90% **THEN** the system SHALL mark the verification as "Needs Review" and notify human reviewers
3. **WHEN** AI confidence is below 50% **THEN** the system SHALL automatically reject the verification with detailed feedback
4. **WHEN** the decision is made **THEN** the system SHALL emit a VerificationCompleted event with decision, confidence, and reasoning
5. **WHEN** the decision is logged **THEN** the system SHALL store the complete AI response on-chain as an Ed25519-signed message for auditability

### User Story 6: Prompt Engineering and Context Building

**As the** AI prompt builder  
**I want to** construct detailed prompts that include task requirements, evidence, and evaluation criteria  
**So that** the AI model has sufficient context to make accurate verification decisions

#### Acceptance Criteria

1. **WHEN** building the prompt **THEN** the system SHALL include the original task description from the escrow contract
2. **WHEN** building the prompt **THEN** the system SHALL include all submitted evidence with clear labels and formatting
3. **WHEN** building the prompt **THEN** the system SHALL include specific evaluation criteria such as completeness, quality, and requirement matching
4. **WHEN** building the prompt **THEN** the system SHALL request a structured JSON response with decision, confidence, and reasoning fields
5. **WHEN** the prompt exceeds token limits **THEN** the system SHALL prioritize the most relevant evidence and truncate less important content

### User Story 7: AI Result Authentication and Security

**Implementation Status**: ðŸ”„ **PLANNED** - Ed25519 signature verification not yet implemented

**As a** security-conscious user  
**I want** AI verification results to be cryptographically signed  
**So that** I can verify the authenticity of verification decisions and prevent tampering

#### Acceptance Criteria

1. ðŸ”„ **WHEN** the AI generates a verification result **THEN** the system SHALL create an Ed25519 signature of the result using the AI service's private key *(PLANNED)*
2. ðŸ”„ **WHEN** the result is stored on-chain **THEN** the system SHALL include the signature alongside the verification decision *(PLANNED)*
3. ðŸ”„ **WHEN** a user queries verification results **THEN** the system SHALL provide the signature for independent verification *(PLANNED)*
4. ðŸ”„ **WHEN** signature verification is performed **THEN** the system SHALL use the AI service's public key to validate authenticity *(PLANNED)*
5. ðŸ”„ **WHEN** signature verification fails **THEN** the system SHALL reject the result and trigger a re-verification *(PLANNED)*

### User Story 8: Feedback Generation and Iteration Support

**As a** freelancer whose work was rejected  
**I want** detailed AI-generated feedback explaining what was missing  
**So that** I can improve my submission and resubmit for verification

#### Acceptance Criteria

1. **WHEN** my work is rejected **THEN** the system SHALL generate specific feedback identifying which task requirements were not met
2. **WHEN** feedback is generated **THEN** the system SHALL include actionable suggestions for improvement
3. **WHEN** I view the feedback **THEN** the system SHALL display it in a clear, structured format with bullet points
4. **WHEN** I resubmit evidence **THEN** the system SHALL include the previous feedback in the AI prompt to check for improvements
5. **WHEN** multiple resubmissions occur **THEN** the system SHALL track the iteration history and display progress over time

### User Story 9: Performance Optimization and Caching

**As the** verification system  
**I want to** optimize AI verification performance through caching and parallel processing  
**So that** I can handle high volumes of verification requests efficiently

#### Acceptance Criteria

1. **WHEN** identical evidence is submitted multiple times **THEN** the system SHALL return cached verification results without calling the AI API
2. **WHEN** multiple verification requests arrive simultaneously **THEN** the system SHALL process them in parallel up to a concurrency limit of 10
3. **WHEN** verification completes **THEN** the system SHALL cache the result for 24 hours with the evidence hash as the cache key
4. **WHEN** the cache is full **THEN** the system SHALL evict the least recently used entries to make space for new results
5. **WHEN** verification takes longer than 30 seconds **THEN** the system SHALL return a timeout error and queue the request for retry

### User Story 10: Error Handling and Fallback Mechanisms

**Implementation Status**: ðŸ”„ **PARTIALLY IMPLEMENTED** - Basic retry logic implemented, fallback chain planned

**As the** verification system  
**I want** robust error handling and fallback mechanisms  
**So that** verification requests succeed even when primary services are unavailable

#### Acceptance Criteria

1. âœ… **WHEN** Arcanum.ai returns an error **THEN** the system SHALL retry the request up to 3 times with exponential backoff *(IMPLEMENTED)*
2. ðŸ”„ **WHEN** all Arcanum.ai retries fail **THEN** the system SHALL fall back to OpenAI as the secondary provider *(PLANNED - No fallback chain)*
3. ðŸ”„ **WHEN** OpenAI fails **THEN** the system SHALL fall back to Claude as the tertiary provider *(PLANNED - No fallback chain)*
4. ðŸ”„ **WHEN** Claude fails **THEN** the system SHALL fall back to Gemini as the quaternary provider *(PLANNED - No fallback chain)*
5. âœ… **WHEN** all AI providers fail **THEN** the system SHALL mark the verification as "Needs Review" and notify administrators *(IMPLEMENTED)*
6. ðŸ”„ **WHEN** rate limits are hit **THEN** the system SHALL queue the request and retry after the rate limit window expires *(PLANNED)*

### User Story 11: Verification Analytics and Model Improvement

**Implementation Status**: ðŸ”„ **PLANNED** - Analytics and feedback loop not yet implemented

**As a** system administrator  
**I want** to track verification accuracy and collect feedback for model improvement  
**So that** I can continuously enhance the AI verification system

#### Acceptance Criteria

1. ðŸ”„ **WHEN** verifications are completed **THEN** the system SHALL log the decision, confidence, and processing time to analytics *(PLANNED)*
2. ðŸ”„ **WHEN** disputes are resolved **THEN** the system SHALL compare the AI decision with the human arbitrator decision *(PLANNED - Requires dispute resolution)*
3. ðŸ”„ **WHEN** discrepancies are found **THEN** the system SHALL flag the case for prompt engineering review *(PLANNED)*
4. ðŸ”„ **WHEN** accuracy metrics are calculated **THEN** the system SHALL display overall accuracy, precision, and recall on the admin dashboard *(PLANNED)*
5. ðŸ”„ **WHEN** model performance degrades **THEN** the system SHALL send alerts to administrators for investigation *(PLANNED)*

## Technical Requirements

### Arcanum.ai Integration

#### API Configuration
- **Endpoint**: https://api.arcanum.ai/v1/analyze
- **Model**: arcanum-pro (specialized task verification model)
- **Authentication**: API key-based authentication via ARCANUM_API_KEY environment variable
- **Timeout**: 30 seconds per API call
- **Pricing**: $0.05 per verification request

#### Environment Variables
- **ARCANUM_API_KEY**: API key for Arcanum.ai authentication (required)
- **ARCANUM_ENDPOINT**: Custom endpoint URL if using self-hosted instance (optional, defaults to https://api.arcanum.ai/v1/analyze)
- **ARCANUM_TIMEOUT**: Request timeout in milliseconds (optional, defaults to 30000)

#### Request Structure
```json
{
  "task_description": "<task requirements>",
  "evidence": {
    "text": "<text evidence>",
    "images": ["<image_url_1>", "<image_url_2>"],
    "documents": ["<document_url_1>"],
    "urls": ["<url_1>"]
  },
  "evaluation_criteria": {
    "completeness": true,
    "quality": true,
    "authenticity": true
  },
  "response_format": "structured"
}
```

#### Response Parsing
- Extract verification decision from structured JSON response
- Parse confidence score as a float between 0.0 and 1.0
- Extract reasoning text for feedback generation
- Handle malformed responses with error recovery

### Evidence Analysis Pipeline

#### Supported Evidence Types
- **Text**: Plain text, markdown, code snippets
- **Images**: JPEG, PNG, WebP (max 5MB per image)
- **Documents**: PDF, DOCX, TXT (max 10MB per document)
- **URLs**: Web pages, GitHub repositories, deployed applications

#### Processing Steps
1. **Retrieval**: Fetch evidence from IPFS using the stored CID
2. **Validation**: Check file size, format, and content type
3. **Preprocessing**: Extract text, resize images, chunk large files
4. **Request Construction**: Build comprehensive request with task context and evidence
5. **AI Analysis**: Send request to Arcanum.ai and await response
6. **Result Processing**: Parse response, calculate confidence, generate feedback
7. **Storage**: Store result on-chain with Ed25519 signature

### Verification Decision Logic

#### Confidence Thresholds
- **High Confidence (â‰¥90%)**: Automatic approval, immediate fund release
- **Medium Confidence (50-89%)**: Human review required, funds remain locked
- **Low Confidence (<50%)**: Automatic rejection, detailed feedback provided

#### Decision Factors
- **Requirement Matching**: Does evidence demonstrate all task requirements are met?
- **Quality Assessment**: Is the work quality acceptable for the agreed payment?
- **Completeness**: Are all deliverables present and functional?
- **Authenticity**: Does the evidence appear genuine and not plagiarized?

### Performance Requirements
- **Verification Latency**: Complete verification within 30 seconds for 95% of requests
- **Throughput**: Handle 100 concurrent verification requests
- **Cache Hit Rate**: Achieve 20% cache hit rate for duplicate evidence
- **API Cost**: Keep average cost per verification below $0.10

### Security Requirements
- **Signature Verification**: All AI results signed with Ed25519 private key
- **Input Validation**: Sanitize all evidence to prevent prompt injection attacks
- **Rate Limiting**: Limit verification requests to 10 per user per minute
- **Access Control**: Only escrow participants can trigger verification

### Error Handling Requirements
- **Retry Logic**: Exponential backoff with jitter (1s, 2s, 4s delays)
- **Fallback Chain**: Arcanum.ai â†’ OpenAI â†’ Claude â†’ Gemini â†’ Human Review
- **Timeout Handling**: Return timeout error after 30 seconds, queue for retry
- **Error Logging**: Log all errors with request ID, timestamp, and error details
- **Provider-Specific Error Codes**: Handle Arcanum.ai error codes (401: Invalid API key, 429: Rate limit exceeded, 503: Service unavailable)

## Integration Points

### IPFS Integration
- Retrieve evidence files using IPFS CID
- Cache retrieved content locally for 1 hour
- Handle IPFS gateway failures with multiple gateway fallbacks

### Smart Contract Integration
- Read escrow task description and requirements from on-chain state
- Write verification result to escrow account with signature
- Emit VerificationCompleted event for off-chain indexing

### Notification Service Integration
- Send real-time notifications to freelancer when verification completes
- Send notifications to client when human review is required
- Send alerts to administrators when all AI providers fail

### Analytics Integration
- Log verification metrics (latency, confidence, decision) to analytics database
- Track AI provider usage and costs
- Monitor accuracy through dispute resolution feedback loop
